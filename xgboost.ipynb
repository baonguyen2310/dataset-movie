{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XiE1MyUIBBdR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.models import Word2Vec\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBR6qQELC5sQ",
    "outputId": "3fd85165-1626-48ec-e789-c71a0bbe4df2"
   },
   "outputs": [],
   "source": [
    "#Tiền xử lý dữ liệu\n",
    "def tokenize_vietnamese_text(text):\n",
    "    return text.split()\n",
    "\n",
    "def filter_not_alphabet_or_number(text):\n",
    "    return re.sub('\\W+', ' ', text)\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = \"du_lieu.csv\"  # Thay \"path_to_your_csv_file.csv\" bằng đường dẫn tới file CSV thực tế\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Lấy dữ liệu từ cột có nhãn là \"Question\"\n",
    "text_column = df[\"Question\"]\n",
    "\n",
    "# Tách từng dòng của cột \"Question\"\n",
    "x_data = []\n",
    "for text in text_column:\n",
    "    text = filter_not_alphabet_or_number(text)\n",
    "    x_data.append(text)\n",
    "\n",
    "# print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I25Nm0s3Q5GP",
    "outputId": "520885c7-c1c0-4218-86ff-41208605dfde"
   },
   "outputs": [],
   "source": [
    "# Đánh nhãn\n",
    "y_data = df[\"lable\"]\n",
    "\n",
    "labeling_answer = {}\n",
    "time_appear = {}\n",
    "labeling_count = 0\n",
    "new_y_data = []\n",
    "for intent in y_data:\n",
    "    if intent not in labeling_answer:\n",
    "      labeling_answer[intent] = labeling_count\n",
    "      labeling_count += 1\n",
    "      time_appear[intent] = 0\n",
    "    else:\n",
    "      time_appear[intent] += 1\n",
    "    new_y_data.append(labeling_answer[intent])\n",
    "\n",
    "# print(new_y_data)\n",
    "# print('labeling_answer: {}'.format(labeling_answer))\n",
    "# print(time_appear)\n",
    "# print(len(new_y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cE_FGDca-NFm",
    "outputId": "d7b28994-a35e-41e8-e962-fcb8ad7787cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 69 148 156 ... 102 140  10]\n"
     ]
    }
   ],
   "source": [
    "input_data = x_data\n",
    "output_data = new_y_data\n",
    "\n",
    "# print(x_data[:-5])\n",
    "# print(output_data[:-5])\n",
    "\n",
    "# Encoding responses into numerical labels\n",
    "labels = new_y_data\n",
    "\n",
    "# Data preprocessing: TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(input_data)\n",
    "\n",
    "# Word embeddings using Word2Vec\n",
    "sentences = [sent.split() for sent in input_data]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=1)\n",
    "\n",
    "# Create word embeddings for each sentence\n",
    "X_w2v = []\n",
    "for sent in sentences:\n",
    "    embeddings = [word2vec_model.wv[word] for word in sent if word in word2vec_model.wv]\n",
    "    if embeddings:\n",
    "        avg_embedding = np.mean(embeddings, axis=0)\n",
    "        X_w2v.append(avg_embedding)\n",
    "    else:\n",
    "        # If a sentence contains no known words, add a zero vector\n",
    "        X_w2v.append(np.zeros(word2vec_model.vector_size))\n",
    "\n",
    "X_w2v = np.array(X_w2v)\n",
    "\n",
    "# Combine TF-IDF and Word2Vec features\n",
    "X_combined = np.hstack((X_tfidf.toarray(), X_w2v))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, random_state=42)\n",
    "print(np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0.1, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0.1, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=0.1, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob',\n",
       "              predictor=None, ...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.1,\n",
    "    min_child_weight=1,\n",
    "    objective='multi:softmax',\n",
    "    eval_metric='logloss',\n",
    "    tree_method='gpu_hist'\n",
    ")\n",
    "\n",
    "# Huấn luyện mô hình và đảm bảo số lượng dữ liệu trong X_test và y_test khớp với số lượng đã sử dụng\n",
    "model.fit(X_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác trên tập kiểm tra: 0.6848484848484848\n",
      "Báo cáo phân loại:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.89        48\n",
      "           1       0.82      0.90      0.86        60\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       0.44      0.47      0.45        15\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.41      0.71      0.52        17\n",
      "           6       0.60      0.50      0.55         6\n",
      "           7       0.56      0.42      0.48        12\n",
      "           8       0.67      0.29      0.40         7\n",
      "           9       0.63      0.67      0.65        18\n",
      "          10       0.33      0.20      0.25         5\n",
      "          11       0.33      0.22      0.27         9\n",
      "          12       0.75      0.50      0.60         6\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.64      0.82      0.72        28\n",
      "          15       1.00      0.67      0.80         3\n",
      "          16       0.80      1.00      0.89         8\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       0.67      0.75      0.71         8\n",
      "          19       1.00      0.67      0.80         3\n",
      "          20       0.60      0.75      0.67         4\n",
      "          21       0.62      0.56      0.59         9\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      0.33      0.50         3\n",
      "          24       0.62      0.56      0.59         9\n",
      "          25       1.00      0.25      0.40         4\n",
      "          26       0.35      0.50      0.41        12\n",
      "          27       0.60      1.00      0.75         3\n",
      "          28       0.25      0.25      0.25         4\n",
      "          29       0.61      0.73      0.67        15\n",
      "          30       1.00      0.75      0.86        12\n",
      "          31       1.00      0.25      0.40         4\n",
      "          32       1.00      0.33      0.50         3\n",
      "          33       0.67      0.40      0.50         5\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       1.00      1.00      1.00         4\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       0.68      0.83      0.75        23\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.67      0.67      0.67         3\n",
      "          42       0.67      0.50      0.57         8\n",
      "          43       0.68      0.75      0.71        20\n",
      "          44       0.80      0.44      0.57         9\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.67      1.00      0.80         2\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.67      1.00      0.80         2\n",
      "          50       0.75      0.75      0.75         4\n",
      "          51       1.00      0.67      0.80         3\n",
      "          52       1.00      1.00      1.00         2\n",
      "          54       0.50      0.33      0.40         3\n",
      "          55       0.80      1.00      0.89         4\n",
      "          56       1.00      1.00      1.00         1\n",
      "          57       0.60      1.00      0.75         3\n",
      "          58       1.00      0.50      0.67         4\n",
      "          59       1.00      1.00      1.00         3\n",
      "          60       0.50      1.00      0.67         2\n",
      "          61       0.75      0.82      0.78        11\n",
      "          62       0.75      1.00      0.86         3\n",
      "          63       1.00      0.33      0.50         3\n",
      "          64       1.00      1.00      1.00         3\n",
      "          65       1.00      1.00      1.00         3\n",
      "          66       1.00      1.00      1.00         3\n",
      "          67       1.00      1.00      1.00         3\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       0.67      0.33      0.44         6\n",
      "          71       0.75      1.00      0.86         3\n",
      "          72       1.00      1.00      1.00         1\n",
      "          73       0.67      0.67      0.67         3\n",
      "          74       0.67      0.60      0.63        10\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.50      1.00      0.67         1\n",
      "          77       1.00      0.67      0.80         3\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         1\n",
      "          80       0.33      1.00      0.50         1\n",
      "          81       0.89      1.00      0.94         8\n",
      "          82       0.33      0.50      0.40         2\n",
      "          83       1.00      1.00      1.00         4\n",
      "          84       1.00      1.00      1.00         2\n",
      "          85       1.00      0.75      0.86         8\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.60      1.00      0.75         3\n",
      "          88       0.50      0.50      0.50         2\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.36      0.45      0.40        11\n",
      "          91       1.00      0.75      0.86         4\n",
      "          92       1.00      1.00      1.00         4\n",
      "          93       0.75      0.60      0.67         5\n",
      "          94       0.40      0.50      0.44         4\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         5\n",
      "          97       1.00      1.00      1.00         1\n",
      "          98       0.88      1.00      0.93        14\n",
      "          99       1.00      1.00      1.00         1\n",
      "         100       1.00      1.00      1.00         1\n",
      "         101       0.50      0.25      0.33         4\n",
      "         102       0.60      0.75      0.67        12\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         1\n",
      "         105       0.60      0.60      0.60         5\n",
      "         106       0.00      0.00      0.00         2\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.67      0.50      0.57         4\n",
      "         109       0.12      0.33      0.18         3\n",
      "         110       0.00      0.00      0.00         2\n",
      "         111       0.67      0.50      0.57         4\n",
      "         112       1.00      0.67      0.80         3\n",
      "         113       1.00      0.50      0.67         2\n",
      "         114       0.50      1.00      0.67         4\n",
      "         115       0.67      0.67      0.67         3\n",
      "         116       1.00      0.67      0.80         3\n",
      "         117       0.60      0.60      0.60         5\n",
      "         118       0.43      1.00      0.60         3\n",
      "         119       0.64      1.00      0.78         7\n",
      "         120       1.00      0.75      0.86         4\n",
      "         121       0.00      0.00      0.00         6\n",
      "         122       0.50      0.50      0.50         2\n",
      "         123       1.00      0.67      0.80         3\n",
      "         124       1.00      0.25      0.40         4\n",
      "         125       1.00      0.33      0.50         3\n",
      "         126       0.20      0.33      0.25         3\n",
      "         127       0.50      0.50      0.50         6\n",
      "         128       0.50      0.25      0.33         4\n",
      "         129       0.88      1.00      0.93         7\n",
      "         130       0.50      0.80      0.62         5\n",
      "         131       0.40      0.50      0.44         4\n",
      "         132       0.50      1.00      0.67         1\n",
      "         133       1.00      0.50      0.67         2\n",
      "         134       0.83      0.62      0.71         8\n",
      "         135       1.00      1.00      1.00         2\n",
      "         136       0.50      1.00      0.67         2\n",
      "         137       0.60      1.00      0.75         3\n",
      "         138       0.80      0.80      0.80         5\n",
      "         139       1.00      0.75      0.86         4\n",
      "         140       0.75      0.50      0.60         6\n",
      "         141       1.00      0.40      0.57         5\n",
      "         142       1.00      0.25      0.40         4\n",
      "         143       1.00      0.50      0.67         2\n",
      "         144       1.00      1.00      1.00         2\n",
      "         145       1.00      0.50      0.67         2\n",
      "         146       1.00      1.00      1.00         3\n",
      "         147       1.00      1.00      1.00         2\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       1.00      0.33      0.50         3\n",
      "         150       1.00      0.67      0.80         3\n",
      "         151       1.00      0.20      0.33         5\n",
      "         152       0.90      1.00      0.95        18\n",
      "         153       1.00      0.50      0.67         2\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.40      0.67      0.50         3\n",
      "         156       1.00      1.00      1.00         2\n",
      "         157       1.00      1.00      1.00         1\n",
      "         158       1.00      1.00      1.00         2\n",
      "         159       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.68       825\n",
      "   macro avg       0.69      0.64      0.63       825\n",
      "weighted avg       0.72      0.68      0.68       825\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baosp\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\baosp\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\baosp\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\baosp\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\baosp\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\baosp\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán nhãn trên tập kiểm tra\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình bằng độ chính xác và báo cáo phân loại\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Độ chính xác trên tập kiểm tra:\", accuracy)\n",
    "\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "print(\"Báo cáo phân loại:\\n\", classification_report_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "wBPGMIrUBiwx",
    "outputId": "2ce1fa38-22dc-4cd8-8d8a-56a1e4fd5ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  xin chào\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Chào bạn, trường đại học sư phạm kỹ thuật hưng yên có thể giúp gì cho bạn?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  Các ngành đào tạo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Năm 2021, nhà trường tuyển sinh 22 ngành đào tạo. các ngành này đều là những ngành hot đang được xã hội tìm kiếm nguồn nhân lực chất lượng cao đó đó cơ hội việc làm sau khi tốt nghiệp là rất lớn. nhà trường có đội ngũ giảng viên trình độ chuyên môn cao, cơ sở vật chất khang trang hiện đại đảm bảo chất lượng đào tạo tốt nhất cho sinh viên của mình. Em tham khảo thêm tại đây để xem chi tiết nhé: http://www.utehy.edu.vn/#/news-list/news-detail/fc2bd95a-0ec4-4359-a980-05cfcd310a80 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "# Get answer by id\n",
    "def getAnswer(id):\n",
    "  keys = [k for k, v in labeling_answer.items() if v == id]\n",
    "  if len(keys) == 1:\n",
    "    answer = df.loc[df['lable'] == keys[0]]\n",
    "    return answer.iloc[0, 1]\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "# Chatbot function\n",
    "def chatbot(query):\n",
    "    query_vectorized_tfidf = vectorizer.transform([query])\n",
    "    query_vectorized_w2v = []\n",
    "    for word in query.split():\n",
    "        if word in word2vec_model.wv:\n",
    "            query_vectorized_w2v.append(word2vec_model.wv[word])\n",
    "    if query_vectorized_w2v:\n",
    "        query_vectorized_w2v = np.mean(query_vectorized_w2v, axis=0)\n",
    "    else:\n",
    "        # If no known words in the query, use a zero vector\n",
    "        query_vectorized_w2v = np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "    query_vectorized_combined = np.hstack((query_vectorized_tfidf.toarray(), query_vectorized_w2v.reshape(1, -1)))\n",
    "    response_label = model.predict(query_vectorized_combined)[0]\n",
    "    response = getAnswer(response_label)\n",
    "    return response\n",
    "\n",
    "# Test the chatbot\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    response = chatbot(user_input)\n",
    "    print(\"Chatbot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
